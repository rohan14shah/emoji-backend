The goal for this project is to explore how language embeddings and fine-tuning can connect emotional intent in everyday connections, through the use of emojis.
Technically, I created two main datasets: one for emoji data and one for text inputs. Both datasets I found on Kaggle. The emoji dataset included each emoji’s unicode, description, category, and a sentiment score ranging from -1 to 1. The text dataset contained short sentences labeled with emotion. I cleaned both datasets, normalized the emoji sentiment values, and removed duplicate rows. In order to clean the text dataset, I used the code that was given in the Kaggle community as it required comprehensive knowledge of SparkContext and SQLContext. 
I used the SentenceTransformers library and the all-MiniLM-L6-v2 model to create embedding vectors for each emoji. I chose the MiniLM model as it's the most popular one available on HuggingFace, and is shown to be quick and efficient. In the model, each embedding represents the meaning of an emoji in numerical form, allowing comparison with sentence embeddings later. Once the emoji embeddings were generated, I normalized them and stored them using FAISS (Facebook AI Similarity Search). FAISS, recommended to me from ChatGPT, builds an index that similarity searches between vectors extremely fast, which is important when thousands of emojis are compared against a user’s sentence in real time. 
Moving away from Colab, I moved to VSCode. For the backend, I used FastAPI because it is lightweight and is really popular with Python machine learning models. The backend loads the FAISS index and metadata files (emoji_vectors.npy, emoji_meta.parquet, and emoji.index) and uses the same transformer model to encode new user text. Each sentence from the input paragraph is embedded and compared against the emoji vectors to find the top matches. I also applied a sentiment-weighted adjustment that slightly boosts emojis whose sentiment values are closer to the text’s predicted tone. This makes the recommendations more emotionally accurate instead of purely semantic.
To display the results, I built a frontend with Lovable AI. The interface allows a user to paste a paragraph, press Annotate, and automatically see one or more emojis after each sentence if the similarity score is above a set threshold.
 I chose this structure because it combines NLP embeddings, efficient retrieval with FAISS, and sentiment fine-tuning in a real, interactive system. The final model converts natural language into an emotion-aware visual form by predicting emojis that match both meaning and tone.
However, most importantly, Loveable AI was the interface for me, as it allowed my frontend to be what I consider “pretty.”

